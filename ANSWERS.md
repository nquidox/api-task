# Часть 1:

## 1. Серверная часть на Go (Backend).

Реализовано в коде.

## 2. Оптимизация кода. Опишите, как вы бы оптимизировали производительность.

* Оптимизировать логику построения приложения под его узкое место. Например, если приложение работает с БД, то выстраивать запросы с минимальным откликом, чтоб снизить количество возможных блокировок.
* Распараллелить то, что возможно и необходимо. Можно создать пул обработчиков данных и для их работы использовать брокеры сообщений, например RabbitMQ или Kafka.
* Использвать различного рода кэширование, например кв-хранилища типа redis.
* Использовать профилировщик pprof и бенчмарки для выявления проблемных мест в приложении.
* Использовать подходящие структуры данных и алгоритмы. Для выбора поможет пункт выше.
* Стараться не делать монолитное приложение без необходимости.
* Использование различных протоколов, например HTTP/2, gRPC для ускорения передачи данных.




## Часть 2: Работа с PostgreSQL

### 3. Проектирование базы данных

* Создадим 3 таблицы в БД, для пользователей, продуктов и заказов. Для примера использую синтаксис PostgreSQL.
```postgresql
CREATE TABLE users (
id BIGSERIAL PRIMARY KEY,
username VARCHAR(100),
email VARCHAR(100) NOT NULL UNIQUE
);

CREATE TABLE products (
id BIGSERIAL PRIMARY KEY,
product_name VARCHAR(100) NOT NULL,
price DECIMAL(10, 2) NOT NULL,
in_stock INT NOT NULL
);

CREATE TABLE orders (
id BIGSERIAL PRIMARY KEY,
user_id BIGINT NOT NULL,
product_id BIGINT NOT NULL,
amount INT NOT NULL,
FOREIGN KEY (user_id) REFERENCES users(id),
FOREIGN KEY (product_id) REFERENCES products(id)
);
```

PostgreSQL не создает индексы на внешние ключи автоматически, добавим их:
```postgresql
CREATE INDEX idx_user_id ON orders(user_id);
CREATE INDEX idx_product_id ON orders(product_id);
```

Для сохранения целостности данных можно применять:

#### Ограничения.

Ограничения в виде первичных и внешних ключей, а также специальные параметры, например UNIQUE. Первичные ключи всегда уникальны и индексируются, их удобно использовать для джоинов. Внешние ключи гарантируют, что значения по ним существуют, а также они создают связи между данными. Это полезно для разных операций, например для каскадного удаления данных, чтоб в БД не оставались неиспользуемые данные.


#### Индексы.

Позволяют ускорять выполнение запросов. Индексы лучше всего выставлять для тех полей, которые будут чаще всего использоваться:
  * поля, указываемые для JOIN-ов,
  * поля для условий WHERE,
  * поля для группировки GROUP BY и сортировки ORDER BY.

Индексы могут быть составными (из нескольких полей). Индексировать все подряд плохая практика, так как индексирование создает дополнительную нагрузку на БД.


#### Нормализация.
Применяется для снижения избыточности хранимых данных. Отсутствие дублирования позволяет в разных частях базы за счет связей получать одинаковые данные.
В примере 3 таблицы соответствуют 3 нормальной форме, когда все неключевые данные хранятся в отдельных таблицах.
Например, мы можем создать дополнительную таблицу избранных торваров пользователя:
```postgresql
    CREATE TABLE favourite (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL,
    product_id BIGINT NOT NULL,
    FOREIGN KEY (user_id) REFERENCES users(id),
    FOREIGN KEY (product_id) REFERENCES products(id)
    );
```
Таким образом, получаем таблицу, которая хранит только связи, а всю информацию получаем из других таблиц.

#### Триггеры.

Специальные процедуры, которые срабатывают при указанных условиях. С помощью триггеров, например, можно сделать проверку данных перед вставкой или автоматически обновить какие-то данные при обновлении других. В своей практике не использовал, так как старался держать логику отдельно, данные отдельно. А еще забытые триггеры могут давать "непредсказуемое поведение", если про них забыть.


#### Транзакции.
Последовательность операций, которые выполняются как одно целое. У транзакций выделяют свойства ACID:
1) Атомарность - гарантия, что выполнятся все запросы, либо произойдет откат состояния.
2) Согласованность - данные в базе будут изменены только в случае успешной транзацкии, промежуточные состояния не допускаются.
3) Изолированность - выполняемые параллельно транзакции не должны влиять друг на друга.
4) Долговечность - после завершения транзакции данные в базе должны сохранятся даже после сбоя в системе. Реализуется через резервное копирование и журналирование.

Уровни изоляции транзакций:
1) Read uncommited, так же известное как dirty read. На этом уровне доступно чтение данных, которое может быть изменено другими транзакциями, однако такой тип транзакции имеет наивысшую производительность.
2) Read committed - на этом уровне грязное чтение уже невозможно, однако при повторном чтении данных повторяемость не гарантируется.
3) Repeatable read - в рамках такой транзакции повторяемое чтение будет давать одинаковый результат. Возможно фантомное чтение, когда при повторном чтении могут появится новые данные, добавленные другой транзакцией.
4) Serializable - самый строгий уровень, предотвращает грязные, неповторяющиеся и фантомные чтения. Однако из-за блокировок данных сильно снижается производительность.

Транзакции могут приводить к дедлокам, поэтому транзакции необходимо выстраивать таким образом, чтоб они выполнялись за минимально короткое время, использовать подходящий уровень изоляции, выстраивать блокировки в одинаковом порядке, использовать таймауты.

#### Дополнительно:
- Распределение данных. Шардирование - горизонтальное масштабирование, возможно в раздельных базах на разных серверах. Например один шард хранит данные с id с 1 до 10 млн, другой от 10 млн и далее. Партиционирование - осуществляется в рамках одной БД, разделение таблицы на партиции, например, по временным интервалам - данные за 2024 год, 2023 итд.
- Репликация. Создание параллельных экземпляров основной (мастер) базы. Повышает общую отказоустойчивость системы, а так же добавляет возможность балансировки нагрузки. Как правило, запись идет в основную базу, а чтение с реплик.
- Резервное копирование. Хорошо сочетается с предыдущим пунктом, так как очень ресурсозатратный процесс. Выделяют 3 типа:

1) Полное копирование. Самый надежный в плане восстановления и самый медленный в плане копирования. Создает большую нагрузку и поэтому не подходит для частых бэкапов или бэкапов больших баз.
2) Инкрементный. Сначала создается полный бэкап, потом создаются бэкапы только изменений от точки прошлого бэкапа. Можно часто создавать бэкапы, они не создают большой нагрузки и занимают мало места. Основой минус - при восстановлении требуется вся цепочка бэкапов изменений. Если какой-то из промежуточных бэкапов будет поврежден, то все последующие бэкапы так же будут утрачены.
3) Дифференциальный. Промежуточный вариант 1 и 2 варианта. Так же в начале создается полный бэкап, после создаются бэкапы изменений с суммированием прошлых этапов. Таким образом мы получаем независимые друг от друга бэкапы изменений.





### Оптимизация запросов

Запрос, который выводит список всех пользователей и последний заказ для каждого.
```postgresql
SELECT
    u.user_id,
    u.username,
    o.order_id,
    o.order_date,
    o.amount
FROM
    users u
        LEFT JOIN
    orders o ON u.user_id = o.user_id
WHERE
    o.order_date = (
        SELECT MAX(order_date)
        FROM orders
        WHERE user_id = u.user_id
    )
ORDER BY
    u.user_id;
```

Здесь используется подзапрос для выбора последней записи о заказе для пользователя.
В качестве альтернативы написал запрос с созданием временной таблицы с использованием оконной функции:

```postgresql
WITH LastOrders AS (
    SELECT
        o.user_id,
        o.order_id,
        o.order_date,
        ROW_NUMBER() OVER (PARTITION BY o.user_id ORDER BY o.order_date DESC) AS rn
    FROM
        orders o
)
SELECT
    u.user_id,
    u.username,
    lo.order_id,
    lo.order_date
FROM
    users u
LEFT JOIN
    LastOrders lo ON u.user_id = lo.user_id AND lo.rn = 1
ORDER BY
    u.user_id;
```

Для оценки производительности использовал
```postgresql 
EXPLAIN ANALYZE
```
При единичном запуске они выполнялись за сопоставимое время, при многократном повторном использовании второй вариант показывает вдвое быструю производительность.
Для еще большего ускорения можно разбить один сложный запрос на несколько мелких, оставить минимум только для выборки необходимых данных, а дальнейшие манипуляции, такие как соединение данных, сортировка, очередность итп делать уже с помощью кода.





## Часть 3: Контейнеризация с Docker

### 5. Создание контейнера для приложения
* Dockerfile и docker-compose.yaml лежат в репозитории. Для минимизации образ строится только с использованием alpine и приложением. Сборка в несколько этапов позволяет разместить в контейнере только образ линукса alpine и скомпилированного приложения, таким образом в итоговый образ не попадают пакеты и зависомости, необходимые на этапе компиляции. Помимо этого, компиляция проходит с параметрами CGO_ENABLED=0 и -ldflags="-s -w", первый позволяет собрать статический бинарник, отключив линковку с Си-шными библиотеками, второй убирает из бинарника отладочную информацию.


* docker-compose позволяет запускать одновременно несколько контейнеров как единое целое. docker-compose.yaml описывает какие сервисы будут запущены, устанавливает порядок запуска, а также задает необходимые параметры, конфиги и логгирование. Также указывается поведение restart: unless-stopped, чтоб все сервисы автоматически перезапускались, если их не остановить принудительно.

### 6. Автоматизация CI/CD
Сделан экшен в репозитории, его выполнение начнется когда будет добавлена метка новой версии. Включает в себя этапы: запуск тестов и проверка линтерами из golangci-lint, после чего начнется сборка образа, по окончании которой готовый образ будет доступен по ссылке.
```
https://github.com/nquidox/api-task/pkgs/container/api-task
```
Можно запустить как отдельно, так и через docker compose.





## Часть 4: Операционная система и инфраструктура
### 7. Настройка Nginx
Для балансировки нагрузки, можно в конфиге nginx указать группу серверов через апстрим:
```
http {

   upstream backend_servers {
       server backend1.ru;
       server backend2.ru;
       server backend3.ru;
   }

   server {
   listen 80;

        location / {
            proxy_pass http://backend_servers
            #также проксируем заголовки
        }
   }
}
```
Такой конфиг позволит nginx-у равномерно распределять запросы в указанной группе. Дополнительно можно указать параметры least_conn - для передачи запросов наименее загруженному серверу, ip_hash - перенаправлять запросы одного юзера на один и тот же сервер. Отказоустойчивость достигается путем увеличения количества серверов в группе. Также за счет такого проксирования можно выстроить систему CDN.

Для ускорения работы можно кэшировать некоторые данные, например статику.
location /static/ {
expires 30d;
add_header Cache-Control "public, no-transform";
}
Дополнительно можно сжимать данные gzip-ом.

## 8. Микросервисная архитектура

Для коммуникации микросервисов чаще всего используются: REST API, gRPC и брокеры сообщений. Далее уже с применением этих технологий строится архитектура.

Несколько популярных архитектур:
1) API gateway - в этой архитектуре подразумевается, что есть некая единая точка входа для клиента, а все микросервисное взаимодействие уже изолировано за ней. Можно реализовать с помощью апстрима nginx-а. Самый простой пример, это цепочка nginx - микросервис пользователей, который проводит аутентификацию, запрашивает, допустим, по grpc данные от микросервиса заказов и возвращает готовый ответ обратно клиенту. Стоит учитывать, что если какой-то из элементов последовательной обработки запроса выдаст ошибку, то клиент в ответ получит сообщение об ошибке.


2) Client side composition. При такой архитектуре существуют группы микросервисов. Клиентское SPA приложение по необходимости делает запросы к разным группам и само уже формирует интерфейс на основании полученных ответов. Из плюсов - если одна из групп микросервисов даст сбой, то это не повлияет на другие.


3) Server side composition. Похож на предыдущий, только сборка осуществляется на стороне сервера перед отправкой ответа клиенту.


4) Backends for frontends. Разновидность API gateway, для разных клиентов создается отдельный гейтвей, например, один для браузеров, другой для мобильных приложений.

Вариантов построения довольно много, при выборе надо отталкиваться от текущих потребностей с учетом последующего масштабирования. Не обязательно придерживаться конкретных паттернов, главное что надо учитывать это быстродействие и надежность системы в целом.

С системами оркестрации типа Kubernetes и Docker Swarm я знаком поверхносто, напрямую с ними не работал, но в целом представляю для чего они нужны. Напишу кратко, что kubernets - это распределенная система оркестрации контейнеров, позволяет гибко управлять их работой, запускать новые, перезапускать упавшие контейнеры, "безшовно" внедрять сервисы с новым функционалом, откатывать изменения. Также для подов создается внутренняя виртуальная сеть, такая изоляция повышает безопасность взаимодействия микросервисов в общей системе.


